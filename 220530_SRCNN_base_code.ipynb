{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"220530_SRCNN_base_code.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cw7IU2hJG4fm","executionInfo":{"status":"ok","timestamp":1653974984807,"user_tz":-540,"elapsed":2773,"user":{"displayName":"백수민","userId":"11277539835389427967"}},"outputId":"9eb03f84-7f99-478e-9658-d9c417f98b84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["datasetPath = \"./drive/MyDrive/dataset/\"\n","parameterPath = \"./drive/MyDrive/parameters/\""],"metadata":{"id":"ZtWK5DctSxRj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 패키지 선언"],"metadata":{"id":"u4givrajR1MK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYgfvxXBROJY"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.datasets as dataset\n","import torchvision.transforms as transform\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from glob import glob\n","import numpy as np\n","import cv2"]},{"cell_type":"markdown","source":["## DataLoader 정의"],"metadata":{"id":"CH7TRQ_USAes"}},{"cell_type":"code","source":["# Training data loader\n","class TrainDataset(Dataset):\n","    def __init__(self):\n","        patch_size = 32\n","\n","        # 다운로드 받은 모든 이미지 경로 가져오기\n","        inputImgPaths = glob(datasetPath+\"SR_dataset/T91_ILR/*.png\")\n","        labelImgPaths = glob(datasetPath+\"SR_dataset/T91_HR/*.png\")\n","        inputImgPaths.sort()\n","        labelImgPaths.sort()\n","\n","        # 데이터 (패치)를 저장할 리스트 생성\n","        self.inputPatchs = []\n","        self.labelPatchs = []\n","\n","        for idx in range(len(inputImgPaths)):\n","            # 한개 이미지 읽고 정규화 수행\n","            inputImg = np.array(cv2.imread(inputImgPaths[idx]), dtype=np.float32) / 255.\n","            labelImg = np.array(cv2.imread(labelImgPaths[idx]), dtype=np.float32) / 255.\n","\n","            inputImg = np.transpose(inputImg, [2, 0, 1]) # 이미지 차원 변경\n","            labelImg = np.transpose(labelImg, [2, 0, 1]) # [H x W x C] -> [C x H x W]\n","\n","            # 한개 이미지를 여러개의 패치로 변경\n","            self.frameToPatchs(inputImg, labelImg, patch_size)\n","\n","    def __len__(self):\n","        return len(self.inputPatchs)\n","    \n","    def __getitem__(self, idx):\n","        return self.inputPatchs[idx], self.labelPatchs[idx]\n","\n","    def frameToPatchs (self, inputImg=None, labelImg=None, patch_size=32):\n","        channel, height, width = labelImg.shape\n","\n","        numPatchY = height // patch_size\n","        numPatchX = width // patch_size\n","\n","        for yIdx in range(numPatchY):\n","            for xIdx in range(numPatchX):\n","                xStartPos = xIdx * patch_size\n","                xFinalPos = xStartPos + patch_size\n","                yStartPos = yIdx * patch_size\n","                yFinalPos = yStartPos + patch_size\n","\n","                self.inputPatchs.append(inputImg[:, yStartPos:yFinalPos, xStartPos:xFinalPos])\n","                self.labelPatchs.append(labelImg[:, yStartPos:yFinalPos, xStartPos:xFinalPos])\n","\n"],"metadata":{"id":"0X4o7AP1SAWl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Testing data loader\n","class TestDataset(Dataset):\n","    def __init__(self):\n","        patch_size = 32\n","\n","        # 다운로드 받은 모든 이미지 경로 가져오기\n","        inputImgPaths = glob(datasetPath+\"SR_dataset/Set5_ILR/*.bmp\")\n","        labelImgPaths = glob(datasetPath+\"SR_dataset/Set5_HR/*.bmp\")\n","        inputImgPaths.sort()\n","        labelImgPaths.sort()\n","\n","        # 데이터를 저장할 리스트 생성\n","        self.inputImgs = []\n","        self.labelImgs = []\n","        self.imgNames = []\n","\n","        for idx in range(len(inputImgPaths)):\n","            # 한개 이미지 읽고 정규화 수행\n","            inputImg = np.array(cv2.imread(inputImgPaths[idx]), dtype=np.float32) / 255.\n","            labelImg = np.array(cv2.imread(labelImgPaths[idx]), dtype=np.float32) / 255.\n","\n","            inputImg = np.transpose(inputImg, [2, 0, 1]) # 이미지 차원 변경\n","            labelImg = np.transpose(labelImg, [2, 0, 1]) # [H x W x C] -> [C x H x W]\n","\n","            # 이미지 패치를 수행하지 않고 그대로 저장\n","            self.inputImgs.append(inputImg)\n","            self.labelImgs.append(labelImg)\n","            self.imgNames.append(inputImgPaths[idx].split(\"/\")[-1])\n","\n","    def __len__(self):\n","        return len(self.inputImgs)\n","    \n","    def __getitem__(self, idx):\n","        return self.inputImgs[idx], self.labelImgs[idx], self.imgNames[idx]\n","\n"],"metadata":{"id":"G_Wp5SBxSAUm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SRCNN 모델 정의"],"metadata":{"id":"0LN2lxktYEtv"}},{"cell_type":"code","source":["class SRCNN (nn.Module):\n","    def __init__(self):\n","        super(SRCNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, padding=4)\n","        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, padding=0)\n","        self.conv3 = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, padding=2)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","\n","        out = self.relu(self.conv1(x))\n","        out = self.relu(self.conv2(out))\n","        out = self.conv3(out)\n","        return out\n"],"metadata":{"id":"sVPy0Jh9SARN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hyper-parameters 지정"],"metadata":{"id":"IToRkBtAYyMB"}},{"cell_type":"code","source":["network = SRCNN_DEN()\n","batch_size = 16\n","base_learning_rate = 1e-4 #0.0001\n","training_epoch = 30\n","loss_function = nn.MSELoss()\n","\n","optimizer = torch.optim.Adam([{'params':network.conv1_1.parameters()},\n","                            {'params':network.conv2_1.parameters()},\n","                            {'params':network.conv3_1.parameters(), 'lr':base_learning_rate * 0.1}],\n","                            lr = base_learning_rate)\n","\n","train_dataset = TrainDataset()\n","train_dataloader = DataLoader(dataset = train_dataset,\n","                              batch_size = batch_size,\n","                              shuffle = True,\n","                              drop_last = True)"],"metadata":{"id":"grHQJDQeSAOK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training loop w/ GPU\n","- Colab 상단 런타임 - 런타임 유형 변경 - 하드웨어 가속기 에서 GPU 선택 - 저장\n","- !nvidia-smi 명령어로 GPU 할당 여부 확인\n","- network parameter 및 data 유형을 cuda:0으로 설정"],"metadata":{"id":"cm4Bwejnb2vq"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"FKS32o0RqqpM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653974359588,"user_tz":-540,"elapsed":563,"user":{"displayName":"백수민","userId":"11277539835389427967"}},"outputId":"75449931-ea6d-4789-abec-4962c1aea7ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue May 31 05:19:18 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   77C    P0    32W /  70W |   1324MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["network.train()\n","network = network.to('cuda:0')\n","for epoch in range(training_epoch):\n","    avg_cost = 0\n","    total_batch = len(train_dataloader)\n","\n","    for inputImg, labelImg in train_dataloader:\n","        \n","        inputImg = inputImg.to('cuda:0')\n","        labelImg = labelImg.to('cuda:0')\n","\n","        predImg = network(inputImg)\n","\n","        loss = loss_function(predImg, labelImg)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        avg_cost += loss / total_batch\n","\n","    print('Epoch: %d Loss = %f'%(epoch+1, avg_cost))\n","\n","print('Learning finished')          "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"O2WDV6bwb2hv","executionInfo":{"status":"error","timestamp":1653974359589,"user_tz":-540,"elapsed":12,"user":{"displayName":"백수민","userId":"11277539835389427967"}},"outputId":"e707700c-183d-46c1-c9dd-dc41620967e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([16, 3, 32, 32])) that is different to the input size (torch.Size([16, 102, 4, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-cdfc2ee94420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpredImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3259\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3261\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (32) at non-singleton dimension 3"]}]},{"cell_type":"markdown","source":["## Parameter 저장"],"metadata":{"id":"sxmymNfpjiNs"}},{"cell_type":"code","source":["torch.save(network.state_dict(), parameterPath+\"SRCNN.pth\")"],"metadata":{"id":"8qBr4cD5jhx-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PSNR 계산 함수 정의"],"metadata":{"id":"beymdw0vj437"}},{"cell_type":"code","source":["def calc_psnr(origImg, predImg):\n","    return 10. * torch.log10(1. / torch.mean((origImg - predImg)**2))"],"metadata":{"id":"gEe89JNJSAMH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 이미지 복원 품질 측정 및 저장"],"metadata":{"id":"YEyHYGqAkJeF"}},{"cell_type":"code","source":["test_dataset = TestDataset()\n","test_dataloader = DataLoader(dataset = test_dataset, batch_size = 1)\n","bicubic_PSNRs = []\n","srcnn_PSNRs = []\n","\n","network.eval()\n","network = network.to('cpu')\n","\n","for inputImg, labelImg, imgName in test_dataloader:\n","\n","    with torch.no_grad():\n","        predImg = network(inputImg).clamp(0.0, 1.0)\n","\n","    bicubic_PSNRs.append(calc_psnr(labelImg, inputImg))\n","    srcnn_PSNRs.append(calc_psnr(labelImg, predImg))\n","\n","    predImg = np.array(predImg * 255, dtype=np.uint8)\n","    predImg = np.transpose(predImg[0,:,:,:], [1, 2, 0])\n","    cv2.imwrite(datasetPath+\"SR_dataset/Set5_Pred/\"+imgName[0], predImg) # 복원된 이미지 저장\n","\n","print('Average PSNR (bicuic)\\t: %.4fdB'%(sum(bicubic_PSNRs)/len(bicubic_PSNRs)))\n","print('Average PSNR (SRCNN)\\t: %.4fdB'%(sum(srcnn_PSNRs)/len(srcnn_PSNRs)))\n"],"metadata":{"id":"AGVT2U-QSAIt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Torchsummary 패키지를 사용해 SRCNN 복잡도 측정"],"metadata":{"id":"00fDSCyDsa-w"}},{"cell_type":"code","source":["from torchsummary import summary\n","inChannel = 3\n","inWidth = 32\n","inHeight = 32\n","\n","summary(SRCNN(),input_size=(inChannel, inWidth, inHeight), device='cpu')"],"metadata":{"id":"ckatCdnFrvkG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"W7GeXBJ6sydv"},"execution_count":null,"outputs":[]}]}